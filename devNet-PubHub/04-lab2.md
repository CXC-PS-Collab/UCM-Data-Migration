# Lab 2: ROUTE PATTERN and DEPENDENCIES

So you have completed the lab 1 and now that you have understood how to analyse dependencies and export dependency records, lets take one step ahead and export/import more complex/dependent Route Patterns, Route List and Route Groups.

> Naming Conventions:
- **Source Cluster** OR **12.5** OR **Source**: _Points to CUCM 12.5 Cluster_
- **Destination Cluster** OR **14.0** OR **Destination**: _Points to CUCM 14.0 Cluster_

## Data Understanding

1. You will observe that all Route Patterns belong to specific Partitions:
   1. Partitions: ```<siteCode>_<type>_PT```
2. Each Route Pattern has 1 Route List which has 1 Route Group which has 1 SIP trunk 

> Dependency Tree: Route Pattern
![image](https://user-images.githubusercontent.com/40081345/169755205-6f4966a4-af10-4580-9da8-fbb933998799.png)

> Dependency Tree: Route List

![image](https://user-images.githubusercontent.com/40081345/169755500-ae244b84-6087-43bb-b061-bd39efb22743.png)

> Dependency Tree: Route Group

![image](https://user-images.githubusercontent.com/40081345/169755343-7613817c-f6fe-4bb1-ac73-b05145767d8a.png)


From this dependency tree, we could find multiple dependencies are needed to properly import Route patterns.

Hence, in order to export and import Route Patterns, we wil follow below logic:
- Export Logic:
  - Get Route Patterns
  - Get Route List or SIP Trunks (as part of Route Patterns)
  - Get Partition
  - Get Route Group
  - Get SIP Trunk (as part of Route Groups)
- Import Logic:
  - Import SIP Trunk and all dependencies
  - Import Route Group
  - Import Route List
  - Import Partitions
  - Import Route Patterns

Some of the dependent records (Call Manager groups, Device Pools are already imported in the cluster). In production scenario, these dependencies records should also be taken care off.

## Migration Workflow

> **Let's Start Coding**

1. Create and Read Input files:
   1. **sourceCluster.json**: _This file provides details required to connect to source cluster_ 
   
    > Copy the following code to __inputs/sourceCluster.json__
    ```json
    {
        "sourceCUCM": "<Source Cluster IP/Hostname>",
        "username": "devnetXX",
        "password": "devnet@123",
        "version": "12.5",
        "siteCode": ["PODXX"]
    }
    ```

   2. **destinationCluster.json**: _This file provides details required to connect to destination cluster_
   
    > Copy the following code to __inputs/destinationCluster.json__
    ```json
    {
        "cucm": "<Destination Cluster IP/Hostname>",
        "username": "devnetXX",
        "password": "devnet@123",
        "version": "14.0",
        "configsFolders": ["PODXX"]
    }
    ```

    3. Read input JSON files to create AXL Python Objects. These python objects are used to initiate connection and perform operations towards CUCM clusters
   
    > Copy following code to __RP_RL_RG/lab2.py__ to create a Python Object for **Source Cluster**
    ```python
    sourceJsonFile = f"../inputs/sourceCluster.json"
    sourceClusterInputJson = json.load(open(sourceJsonFile))
    ## Creating Source AXL Object
    ucm_source = axl(
        username=sourceClusterInputJson["username"],
        password=sourceClusterInputJson["password"],
        cucm=sourceClusterInputJson["cucm"],
        cucm_version=sourceClusterInputJson["version"],
    )
    ```

    > Copy following code to __RP_RL_RG/lab2.py__ to create a Python Object for **Destination Cluster**
    ```python
    destinationJsonFile=f"../inputs/destinationCluster.json"
    sourceClusterInputJson = json.load(open(destinationJsonFile))
    ## Creating Source AXL Object
    ucm_source = axl(
        username=sourceClusterInputJson["username"],
        password=sourceClusterInputJson["password"],
        cucm=sourceClusterInputJson["cucm"],
        cucm_version=sourceClusterInputJson["version"],
    )
    ```

2. Generate Configuration Patterns:
   1. In order to extract CSS based on site code, we should have extract CSS Names to export data from CUCM
   2. To dynamically create CSS names, we write `generate_config_patterns` func to create Input pattern JSON.
   
    > Copy following code to __RP_RL_RG/lab2.py__ to create generate_config_patterns function
    ```python
    ## Output file to generate config patterns
    dataFilterFile=f"getDataFilter.json"

    def generate_config_patterns():
        """
        Step 1: use this function to dynamically 
        create data that we need to extract from 
        source cluster
        """

        ## Define an empty dictionary object to store all sites data
        allSitesData = {}
        ## Generate the datafilter JSON Content
        for site in sourceClusterInputJson['siteCode']:
            siteSpecificdataFilterDict = {
                "routePatternPartition": [
                    f"{site}-Park_PT",
                    f"{site}_PHNDN_PT",
                    f"{site}_CHK_PT"
                ]
            }

            allSitesData[site] = siteSpecificdataFilterDict

        # Serializing json
        dataFilterDict_JSONobject = json.dumps(allSitesData, indent=4)
        jsonFile = open(dataFilterFile, "w")
        jsonFile.write(dataFilterDict_JSONobject)

        ## Close JSON File
        jsonFile.close()

    ## Execute generate_config_patterns function
    generate_config_patterns()
    ```
    3. Save and run the python file
   
    ```bash
    cd ~/src/DEVWKS-2116/RP_RL_RG
    python3 lab2.py
    ```
    4. _getDataFilter.json_ file will be created which contains list of all CSS that we need to export
    


3. Export Configurations:
   
   1. `SiteDataExport` function contains the logic to `get_route_patterns` followed by `get_route_list` followed by ```get_route_group``` followed by ```get_partition```
   2. 
   > Copy following code to __RP_RL_RG/lab2.py__ to create SiteDateExport function
    ```python
    configExportPath=f"./ConfigExports"

    def SiteDataExport(directory, siteDataFilterContent):
        # Flag = True

        routePatternPartition = (
            siteDataFilterContent["routePatternPartition"]
            if "routePatternPartition" in siteDataFilterContent.keys()
            else []
        )

        ## Store all dependent Route Pattern data
        allRoutePatterns = []

        ## Store all dependent Route List data
        corrRouteListNames= []
        allRouteList = []

        ## Store all dependent Route Group data
        allRouteGroup = []

        ## Store all dependent Partition data
        corrPartitionsNames = []
        allPartitions = []

        for rpt in routePatternPartition:
            try:
                rptResults = ucm_source.get_route_patterns(
                    SearchCriteria={"routePartitionName": rpt}
                )
            except Exception as e:
                print(e)
            else:
                if rptResults == None:
                    continue
                elif type(rptResults) == Fault:
                    continue
                elif type(rptResults["routePattern"]) == list:
                    for patt in rptResults["routePattern"]:
                        rpData = ucm_source.get_route_pattern(uuid=patt["uuid"])["return"][
                            "routePattern"
                        ]
                        allRoutePatterns.append(rpData)
                        if rpData["destination"]:
                            if rpData["destination"]["routeListName"] != None:
                                corrRouteListNames.append(
                                    rpData["destination"]["routeListName"]["_value_1"]
                                )
                            else:
                                corrRouteListNames.append(
                                    rpData["destination"]["gatewayName"]["_value_1"]
                                )
        ## Route List and corresponding Route Groups
        for rl in set(corrRouteListNames):
            rlFound = ucm_source.get_route_list(name=rl)
            if type(rlFound) != Fault:
                ## Extract respective members
                data = rlFound["return"]["routeList"]
                allRouteList.append(data)
                if data["members"] != None:
                    for mem in data["members"]["member"]:
                        rgFound = ucm_source.get_route_group(
                            name=mem["routeGroupName"]["_value_1"]
                        )
                        allRouteGroup.append(rgFound["return"]["routeGroup"])

        ## Collate Partition List
        for rps in allRoutePatterns:
            corrPartitionsNames.append(rps["routePartitionName"]["_value_1"])


        for partition in set(corrPartitionsNames):
            partitionFound = ucm_source.get_partition(name=partition)
            if type(partitionFound) != Fault:
                allPartitions.append(partitionFound["return"]["routePartition"])

        # Write Results
        write_results(directory, allRoutePatterns, "routepattern")
        write_results(directory, allRouteList, "routelist")
        write_results(directory, allRouteGroup, "routegroup")
        write_results(directory, allPartitions, "partition")

        return True

    ```
    3. To Export Route Patterns , we use `getDataFilter.json` file as input and store all results as
       1. *routepatterns.json*: Export of Route Patterns Configs
       2. *routelist.json*: Export of Route List Configs
       3. *routegroup.json*: Export of Route Group Configs
       4. *partition.json*: Export of Partition Configs
   
    > Copy following code to __RP_RL_RG/lab2.py__ to create export_RP_Dependencies function

    ```python
    def export_RP_Dependencies():
        """
        Step 2: use this function to export
        CSS and its dependent partitions.
        """
        # Read the dataFilter JSON: This JSON is created in step 1
        dataFilterContent = json.load(open(dataFilterFile))
        for siteCode, siteData in dataFilterContent.items():
            configDirectory = f"{configExportPath}/{siteCode}"
            if not os.path.exists(configDirectory):
                os.makedirs(configDirectory)
            logPrint(f"Files will be saved in '{configDirectory}' directory")
            logPrint(f"Fetching data for Site: {siteCode}")

            try:
                SiteDataExport(configDirectory, siteData)
            except Exception as siteExe:
                logPrint(f"Error Occured while exporting configs: {siteExe}")
                traceback.print_exc()
                exit()

            else:
                logPrint(f"Export Completed for Site: {siteCode}. Proceeding..")


    
    export_RP_Dependencies()

    ```
    4. Execute `export_RP_Dependencies` function. Find and Comment `generate_config_patterns` function.
    ```bash
    cd ~/src/DEVWKS-2116/RP_RL_RG
    python3 lab2.py
    ```
   
4. Import Configurations:
  _While importing configs, we need to ensure import order is followed_

   1. In this lab, we have created this import logic dynamically following the import order:
      1. `common/importLogic.json`
         1. This JSON contains the import order of CUCM configs and AXL methods required to import configs
   
      2. `common/importLogic.py`: 
         1. This file contains the `updateConfigs` func which dynamicaly import configuration based on parameters defined in `importLogic.json` file
   
   > Copy following code to __RP_RL_RG/lab2.py__ to create import_RP_Dependencies function on destination cluster

   ```python

    ## Reading import Logic Sheet
    importLogicFile = f"../common/importLogic.json"
    dynamicLogicJson = json.load(open(importLogicFile))

    def import_RP_Dependencies():
        ## iterate over each site folder and push the configurations
        for site in sourceClusterInputJson['siteCode']:
            configDirectory = f"{configExportPath}/{site}"
            logPrint(f"Reading Configs from Directory: {configDirectory}. Proceeding...")
            if os.path.exists(configDirectory):
                logPrint(
                    f"Starting Import for Site: {site} on CUCM: {destinationClusterInputJson['cucm']}"
                )
                try:
                    userAccept = input("Do you want to proceed (Y/n)?")
                except KeyError:
                    print("Invalid input. Existing..")
                    exit()
                else:
                    if userAccept == "Y":
                        try:
                            updateConfigs(configDirectory, ucm_destination, dynamicLogicJson)
                        except Exception as importExe:
                            logPrint(f"Error Occured while Importing: {importExe}")
                            traceback.print_exc()
                            exit()
                        else:
                            logPrint(f"Data Import completed for site: {site}. Proceeding...")
                    else:
                        logPrint(f"invalid response '{userAccept}' received. Exiting...")
                        exit()
    import_RP_Dependencies()
    ```

    2. Execute `import_RP_Dependencies` function. Find and Comment `export_RP_Dependencies` function.
    ```bash
    cd ~/src/DEVWKS-2116/RP_RL_RG
    python3 lab2.py
    ```

Verify Configuration are imported properly by logging into destination CUCM. _This method can also be automated as extension to this script_


> 🥁 **You have successfully completed Lab 2**